import { expect, test } from 'vitest';

import { GeneralTokenizer } from '../tokenizer';

test('tokenizer', () => {
  {
    const tokens = new GeneralTokenizer().tokenize('hello  world,\n AFFiNE');

    expect(tokens).toEqual([
      { term: 'hello', start: 0, end: 5 },
      { term: 'world', start: 7, end: 12 },
      { term: 'affine', start: 15, end: 21 },
    ]);
  }

  {
    const tokens = new GeneralTokenizer().tokenize('ä½ å¥½ä¸–ç•Œï¼Œé˜¿èŠ¬');

    expect(tokens).toEqual([
      {
        end: 2,
        start: 0,
        term: 'ä½ å¥½',
      },
      {
        end: 3,
        start: 1,
        term: 'å¥½ä¸–',
      },
      {
        end: 4,
        start: 2,
        term: 'ä¸–ç•Œ',
      },
      {
        end: 7,
        start: 5,
        term: 'é˜¿èŠ¬',
      },
    ]);
  }

  {
    const tokens = new GeneralTokenizer().tokenize('1é˜¿2èŠ¬');

    expect(tokens).toEqual([
      { term: '1', start: 0, end: 1 },
      { term: 'é˜¿', start: 1, end: 2 },
      { term: '2', start: 2, end: 3 },
      { term: 'èŠ¬', start: 3, end: 4 },
    ]);
  }

  {
    const tokens = new GeneralTokenizer().tokenize('ì•ˆë…•í•˜ì„¸ìš” ì„¸ê³„');

    expect(tokens).toEqual([
      {
        end: 2,
        start: 0,
        term: 'ì•ˆë…•',
      },
      {
        end: 3,
        start: 1,
        term: 'ë…•í•˜',
      },
      {
        end: 4,
        start: 2,
        term: 'í•˜ì„¸',
      },
      {
        end: 5,
        start: 3,
        term: 'ì„¸ìš”',
      },
      {
        end: 8,
        start: 6,
        term: 'ì„¸ê³„',
      },
    ]);
  }

  {
    const tokens = new GeneralTokenizer().tokenize('ãƒãƒ­ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰');

    expect(tokens).toEqual([
      { term: 'ãƒãƒ­', start: 0, end: 2 },
      { term: 'ãƒ­ãƒ¼', start: 1, end: 3 },
      { term: 'ãƒ¼ãƒ¯', start: 2, end: 4 },
      { term: 'ãƒ¯ãƒ¼', start: 3, end: 5 },
      { term: 'ãƒ¼ãƒ«', start: 4, end: 6 },
      { term: 'ãƒ«ãƒ‰', start: 5, end: 7 },
    ]);
  }

  {
    const tokens = new GeneralTokenizer().tokenize('ã¯ã‚ãƒ¼ã‚ãƒ¼ã‚‹ã©');

    expect(tokens).toEqual([
      { term: 'ã¯ã‚', start: 0, end: 2 },
      { term: 'ã‚ãƒ¼', start: 1, end: 3 },
      { term: 'ãƒ¼ã‚', start: 2, end: 4 },
      { term: 'ã‚ãƒ¼', start: 3, end: 5 },
      { term: 'ãƒ¼ã‚‹', start: 4, end: 6 },
      { term: 'ã‚‹ã©', start: 5, end: 7 },
    ]);
  }

  {
    const tokens = new GeneralTokenizer().tokenize('ğŸ‘‹1ï¸âƒ£ğŸšªğŸ‘‹ğŸ¿');

    expect(tokens).toEqual([
      { term: 'ğŸ‘‹', start: 0, end: 2 },
      { term: '1ï¸âƒ£', start: 2, end: 5 },
      { term: 'ğŸšª', start: 5, end: 7 },
      { term: 'ğŸ‘‹ğŸ¿', start: 7, end: 11 },
    ]);
  }

  {
    const tokens = new GeneralTokenizer().tokenize('1ï¸');

    expect(tokens).toEqual([{ term: '1ï¸', start: 0, end: 2 }]);
  }
});
